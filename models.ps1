# KommunalGPT Models Download (Windows PowerShell)
# Requires PowerShell 5.1 or higher

# Set error action preference
$ErrorActionPreference = "Stop"

# Model list
$Models = @(
    "llama3.1:8b",
    "gemma3:12b", 
    "qwen3:14b",
    "gpt-oss:20b",
    "qwen2.5-coder:14b",
    "llava:13b"
)

# Helper functions
function Write-Info {
    param([string]$Message)
    Write-Host "‚û°Ô∏è  $Message" -ForegroundColor Blue
}

function Write-Success {
    param([string]$Message)
    Write-Host "‚úÖ $Message" -ForegroundColor Green
}

function Write-Warning {
    param([string]$Message)
    Write-Host "‚ö†Ô∏è  $Message" -ForegroundColor Yellow
}

function Write-Error {
    param([string]$Message)
    Write-Host "‚ùå $Message" -ForegroundColor Red
}

function Test-CommandExists {
    param([string]$Command)
    try {
        Get-Command $Command -ErrorAction Stop | Out-Null
        return $true
    }
    catch {
        return $false
    }
}

function Test-OllamaAPI {
    try {
        $response = Invoke-RestMethod -Uri "http://localhost:11434/api/version" -Method Get -TimeoutSec 5 -ErrorAction Stop
        return $true
    }
    catch {
        return $false
    }
}

function Get-OllamaType {
    # Pr√ºfe auf Docker-Container
    try {
        $containers = docker ps --format "{{.Names}}" 2>$null | Where-Object { $_ -eq "ollama" }
        if ($containers) {
            return "docker"
        }
    }
    catch {
        # Docker-Befehl fehlgeschlagen, ignorieren
    }
    
    # Pr√ºfe auf lokale Installation
    if ((Test-CommandExists "ollama") -and (Test-OllamaAPI)) {
        return "local"
    }
    
    return "none"
}

function Start-OllamaContainer {
    try {
        Write-Warning "Ollama-Container l√§uft nicht. Starte tempor√§r..."
        docker compose up -d ollama
        Start-Sleep -Seconds 5
        return $true
    }
    catch {
        Write-Error "Fehler beim Starten des Ollama-Containers"
        return $false
    }
}

function Download-ModelDocker {
    param([string]$ModelName)
    
    try {
        # Pr√ºfe ob Container l√§uft
        $containers = docker ps --format "{{.Names}}" | Where-Object { $_ -eq "ollama" }
        if (-not $containers) {
            if (-not (Start-OllamaContainer)) {
                return $false
            }
        }
        
        # Modell im Container laden
        $result = docker exec -i ollama ollama pull $ModelName
        return $LASTEXITCODE -eq 0
    }
    catch {
        Write-Error "Fehler beim Laden des Modells im Docker-Container: $($_.Exception.Message)"
        return $false
    }
}

function Download-ModelLocal {
    param([string]$ModelName)
    
    try {
        ollama pull $ModelName
        return $LASTEXITCODE -eq 0
    }
    catch {
        Write-Error "Fehler beim Laden des Modells lokal: $($_.Exception.Message)"
        return $false
    }
}

# Main script
try {
    Write-Host "=== KommunalGPT Models Download ===" -ForegroundColor Magenta
    Write-Host ""

    # Erkenne Ollama-Installation (Docker vs. lokal)
    $ollamaType = Get-OllamaType

    switch ($ollamaType) {
        "docker" {
            Write-Success "üê≥ Ollama Docker-Container erkannt. Lade Modelle in Container..."
        }
        "local" {
            Write-Success "üíª Lokale Ollama-Installation erkannt. Lade Modelle lokal..."
        }
        "none" {
            Write-Error "‚ùå Keine funktionierende Ollama-Installation gefunden."
            Write-Info "Bitte starten Sie zuerst das Setup oder stellen Sie sicher, dass Ollama l√§uft."
            exit 1
        }
    }

    Write-Host ""
    Write-Info "Folgende Modelle werden geladen:"
    foreach ($model in $Models) {
        Write-Host "  ‚Ä¢ $model" -ForegroundColor Gray
    }
    Write-Host ""

    $successCount = 0
    $failCount = 0

    # Modelle laden
    foreach ($model in $Models) {
        Write-Info "üîÑ Downloading model: $model..."
        
        $success = $false
        switch ($ollamaType) {
            "docker" {
                $success = Download-ModelDocker -ModelName $model
            }
            "local" {
                $success = Download-ModelLocal -ModelName $model
            }
        }
        
        if ($success) {
            Write-Success "‚úÖ Finished downloading: $model"
            $successCount++
        } else {
            Write-Error "‚ùå Error downloading: $model"
            $failCount++
        }
        
        Write-Host "-----------------------------------" -ForegroundColor DarkGray
    }

    # Zusammenfassung
    Write-Host ""
    Write-Host "=== Download-Zusammenfassung ===" -ForegroundColor Magenta
    Write-Success "Erfolgreich geladen: $successCount Modelle"
    
    if ($failCount -gt 0) {
        Write-Warning "Fehlgeschlagen: $failCount Modelle"
        Write-Info "Bitte √ºberpr√ºfen Sie die Fehler und versuchen Sie es bei Bedarf erneut."
    } else {
        Write-Success "üéâ Alle Modelle erfolgreich geladen!"
    }

}
catch {
    Write-Error "Unerwarteter Fehler beim Laden der Modelle: $($_.Exception.Message)"
    Write-Host "Bitte √ºberpr√ºfen Sie die Ausgabe und versuchen Sie es erneut." -ForegroundColor Red
    exit 1
}
